{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# info_save_index = [0, 6, 12, 18, 24, 30]\n",
    "info_save_index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32]    \n",
    "# info_save_index=[0, 12, 24]\n",
    "\n",
    "ce_data_dir=\"/home/junda/zihan/cbm/data/\"\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 100\n",
    "\n",
    "input_datas = torch.load(ce_data_dir+'ce_training_full.pth')\n",
    "labels = torch.load(ce_data_dir+'ce_training_label_full.pth')\n",
    "input_datas=input_datas # 81527 4096\n",
    "\n",
    "# 暂时取前10000个sample，训练比较快\n",
    "# input_datas = [data[:10000] for data in input_datas]\n",
    "# labels = labels[:10000]\n",
    "\n",
    "written_file=\"ce_result.txt\"\n",
    "\n",
    "\n",
    "vit=False\n",
    "one_item=False\n",
    "# 定义模型\n",
    "class CE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4096, 512)  # 假设每个 tensor 是 1024 维\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, len(labels[0]))  # 10个分类\n",
    "        print(len(labels[0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        # x = torch.sigmoid(self.fc3(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if vit==True:\n",
    "    written_file=\"vit_\"+written_file\n",
    "    info_save_index=[0]\n",
    "\n",
    "results={}\n",
    "inference_result={}\n",
    "\n",
    "for i, index in enumerate(info_save_index):\n",
    "    print(f\"-----------------index {index}-----------------\")\n",
    "    \n",
    "    # 初始化模型、损失函数和优化器\n",
    "    model = CE().to('cuda:0')\n",
    "\n",
    "    # criterion = nn.BCELoss()  # 二元交叉熵损失\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "    if not vit:\n",
    "        input_data=input_datas[i]\n",
    "\n",
    "    # 将数据转换为 Tensor\n",
    "    if vit:\n",
    "        data_tensor = torch.stack(vit_feature_list)\n",
    "    else:\n",
    "        data_tensor = torch.stack(input_data)  # (N, 1024) 假设每个 tensor 是 1024 维\n",
    "    labels_tensor = torch.tensor(labels, device='cuda:0')\n",
    "\n",
    "    # 创建 TensorDataset\n",
    "    dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "\n",
    "    # 创建索引\n",
    "    train_indices = list(range(train_size))\n",
    "    test_indices = list(range(train_size, len(dataset)))\n",
    "\n",
    "    # 使用 Subset 创建子集\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    # vit_feature_list\n",
    "    all_losses=[]\n",
    "    all_f1=[]\n",
    "    all_accuracies = []\n",
    "    classifiy_res_index=[]\n",
    "    gt_res_index=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        classifiy_res_epoch=[]\n",
    "        gt_res_epoch=[]\n",
    "        \n",
    "        model.train()  # 设置模型为训练模式\n",
    "        for inputs, target in train_loader:\n",
    "            inputs = inputs.float().to('cuda:0')\n",
    "            if not one_item:\n",
    "                target = target.float().to('cuda:0')\n",
    "            else:\n",
    "                target=target.unsqueeze(1).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 测试模型\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            total_kl=[]\n",
    "            for inputs, target in test_loader:\n",
    "                inputs = inputs.float().to('cuda:0')\n",
    "                target = target.int()\n",
    "                \n",
    "                predicted = model(inputs)\n",
    "                \n",
    "                classifiy_res_epoch+=predicted\n",
    "                if gt_res_index==[]:\n",
    "                    gt_res_epoch+=target\n",
    "                \n",
    "                for j in range(len(target)):\n",
    "                    if torch.all(target[j] == 0):\n",
    "                        continue\n",
    "                    \n",
    "                    total_kl.append(F.kl_div(torch.log_softmax(predicted[j], dim=0), target[j].float()))\n",
    "\n",
    "        if one_item:\n",
    "            accuracy = 100 * correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')\n",
    "        else:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, kl_div: {sum(total_kl)/len(total_kl):.2f}')\n",
    "        # 保存当前epoch的loss和accuracy\n",
    "        all_losses.append(loss.item())\n",
    "        if one_item:\n",
    "            all_accuracies.append(accuracy)\n",
    "        else:\n",
    "            all_f1.append(sum(total_kl)/len(total_kl))\n",
    "        \n",
    "        classifiy_res_index.append(classifiy_res_epoch)\n",
    "        if gt_res_index==[]:\n",
    "            gt_res_index=gt_res_epoch\n",
    "        \n",
    "    # 将当前 index 的结果存入字典\n",
    "    if vit:\n",
    "        results[0] = {\n",
    "            'losses': all_losses,\n",
    "            'accuracies': all_f1,\n",
    "        }\n",
    "            \n",
    "        inference_result[0] = {\n",
    "            'classifiy_res': classifiy_res_index,\n",
    "            'gt': gt_res_index\n",
    "        }\n",
    "    else:\n",
    "        if one_item:\n",
    "            results[index] = {\n",
    "                'losses': all_losses,\n",
    "                'accuracies': all_accuracies,\n",
    "            }\n",
    "            \n",
    "            inference_result[index] = {\n",
    "                'classifiy_res': classifiy_res_index,\n",
    "                'gt': gt_res_index\n",
    "            }\n",
    "        else:\n",
    "            results[index] = {\n",
    "                'losses': all_losses,\n",
    "                'accuracies': all_f1,\n",
    "            }\n",
    "            \n",
    "            inference_result[index] = {\n",
    "                'classifiy_res': classifiy_res_index,\n",
    "                'gt': gt_res_index\n",
    "            }\n",
    "    torch.save(model.state_dict(), f'./result/ce_model_{index}.pth')\n",
    "    \n",
    "with open(written_file, \"w\") as f:\n",
    "    if one_item:\n",
    "        f.write(\"Index\\tEpoch\\tLoss\\tAccuracy\\n\")\n",
    "    else:\n",
    "        f.write(\"Index\\tEpoch\\tLoss\\tF1\\n\")\n",
    "    for index, metrics in results.items():\n",
    "        for epoch in range(num_epochs):\n",
    "            f.write(f\"{index}\\t{epoch + 1}\\t{metrics['losses'][epoch]:.4f}\\t{metrics['accuracies'][epoch]:.2f}\\n\")\n",
    "\n",
    "print(written_file[:-4]+\".pth\")\n",
    "torch.save(inference_result, written_file[:-4]+\".pth\")\n",
    "\n",
    "print(\"训练完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
