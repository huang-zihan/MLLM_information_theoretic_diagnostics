{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24f0bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "is_qwen=True\n",
    "ce_data_dir = \"../cbm/coco_caption/\"\n",
    "prefix = \"origin\"\n",
    "input_datas = torch.load(ce_data_dir+f'{prefix}coco_caption_ce_val_full_v1.pth')\n",
    "input_datas_image = torch.load(ce_data_dir+f'{prefix}coco_caption_ce_val_image_full_v1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe63f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_index = [73, 98, 188, 190, 232, 235, 258, 267, 275, 287, 297, 309, 316, 338, 365, 423, 470, 480, 483, 657, 1256, 1284, 1323, 1453, 1484, 1654, 1701, 1717, 1726, 1729, 1794, 1796, 1815, 1830, 1871, 1891, 1942, 1954, 2004, 2017, 2037, 2038, 2082, 2096, 2144, 2207, 2282, 2373, 2477, 2502, 2529, 2631, 2778, 2850, 2912, 2941, 2952, 2953, 3013, 3022, 3049, 3067, 3069, 3081, 3185, 3188, 3196, 3202, 3212, 3242, 3296, 3309, 3344, 3355, 3494, 3611, 3687, 3699, 3797, 3824, 3887, 3892, 3999, 4003, 4081, 4819, 4855, 4862, 4980, 5001, 5029, 5096, 5112, 5189, 5280, 5309, 5393, 5523, 5537, 5618, 5669, 5784, 5815, 5854, 5992, 6059, 6063, 6101, 6125, 6312, 6456, 6590, 6597, 6611, 6632, 6666, 6720, 6728, 6731, 6763, 7493, 7523, 7605, 7675, 7694, 7717, 7773, 7778, 7892, 7895, 8206, 8521, 8533, 8689, 8707, 8759, 8802, 8821, 8825, 8921, 8951, 9020, 9021, 9073, 9112, 9134, 9139, 9147, 9251, 9257, 9320, 9363, 9430, 9431, 9440, 9477, 9484, 9490, 9518, 9538, 9541, 9564, 9603, 9606, 9689, 9721, 9740, 9754, 9864, 9932, 9974, 9992]\n",
    "for i in range(len(input_datas)):\n",
    "    input_datas[i]=[x for i, x in enumerate(input_datas[i]) if i not in missing_index]\n",
    "    input_datas_image[i]=[x for i, x in enumerate(input_datas_image[i]) if i not in missing_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0655736",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_qwen=True\n",
    "all_kls = []\n",
    "\n",
    "if is_qwen:\n",
    "    info_save_index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36]\n",
    "else:\n",
    "    info_save_index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b132ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------index 0-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1625783/3401418059.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  js_div = torch.tensor(0.5 * kl_div_text + 0.5 * kl_div_image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append tensor(6.6022e-08)\n",
      "-----------------index 1-----------------\n",
      "append tensor(0.0001)\n",
      "-----------------index 2-----------------\n",
      "append tensor(0.0002)\n",
      "-----------------index 3-----------------\n",
      "append tensor(0.0002)\n",
      "-----------------index 4-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 5-----------------\n",
      "append tensor(0.0006)\n",
      "-----------------index 6-----------------\n",
      "append tensor(0.0012)\n",
      "-----------------index 7-----------------\n",
      "append tensor(0.0016)\n",
      "-----------------index 8-----------------\n",
      "append tensor(0.0016)\n",
      "-----------------index 9-----------------\n",
      "append tensor(0.0016)\n",
      "-----------------index 10-----------------\n",
      "append tensor(0.0013)\n",
      "-----------------index 11-----------------\n",
      "append tensor(0.0006)\n",
      "-----------------index 12-----------------\n",
      "append tensor(0.0004)\n",
      "-----------------index 13-----------------\n",
      "append tensor(0.0004)\n",
      "-----------------index 14-----------------\n",
      "append tensor(0.0010)\n",
      "-----------------index 15-----------------\n",
      "append tensor(0.0012)\n",
      "-----------------index 16-----------------\n",
      "append tensor(0.0010)\n",
      "-----------------index 17-----------------\n",
      "append tensor(0.0011)\n",
      "-----------------index 18-----------------\n",
      "append tensor(0.0015)\n",
      "-----------------index 19-----------------\n",
      "append tensor(0.0011)\n",
      "-----------------index 20-----------------\n",
      "append tensor(0.0010)\n",
      "-----------------index 21-----------------\n",
      "append tensor(0.0015)\n",
      "-----------------index 22-----------------\n",
      "append tensor(0.0023)\n",
      "-----------------index 23-----------------\n",
      "append tensor(0.0025)\n",
      "-----------------index 24-----------------\n",
      "append tensor(0.0029)\n",
      "-----------------index 25-----------------\n",
      "append tensor(0.0009)\n",
      "-----------------index 26-----------------\n",
      "append tensor(0.0019)\n",
      "-----------------index 27-----------------\n",
      "append tensor(0.0006)\n",
      "-----------------index 28-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 29-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 30-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 31-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 32-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 33-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 34-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 35-----------------\n",
      "append tensor(0.0003)\n",
      "-----------------index 36-----------------\n",
      "append tensor(0.0003)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# 初始化结果容器\n",
    "all_metrics = {\n",
    "    # 'kl': [],\n",
    "    # 'cosine': [],\n",
    "    # 'euclidean': [],\n",
    "    'js': [],\n",
    "    # 'pearson': []\n",
    "}\n",
    "\n",
    "# # 添加平滑常数和极小值\n",
    "# EPSILON = 1e-15\n",
    "# MIN_VALUE = 1e-8\n",
    "\n",
    "# for i, index in enumerate(info_save_index):\n",
    "#     print(f\"-----------------index {index}-----------------\")\n",
    "    \n",
    "#     # 加载数据\n",
    "#     input_data = input_datas[i]\n",
    "#     input_data_image = input_datas_image[i]\n",
    "    \n",
    "#     data_tensor = torch.stack(input_data).float()\n",
    "#     data_tensor_image = torch.stack(input_data_image).float()\n",
    "    \n",
    "#     # 创建数据集和加载器\n",
    "#     dataset = TensorDataset(data_tensor, data_tensor_image)\n",
    "#     loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "#     # 初始化指标\n",
    "#     total_js = 0.0\n",
    "#     total_samples = 0\n",
    "    \n",
    "#     for text_batch, image_batch in loader:\n",
    "#         batch_size = text_batch.size(0)\n",
    "        \n",
    "#         # 计算概率分布（添加平滑处理）\n",
    "#         prob_text = F.softmax(text_batch, dim=1) + EPSILON\n",
    "#         prob_image = F.softmax(image_batch, dim=1) + EPSILON\n",
    "        \n",
    "#         # 重新归一化确保有效概率分布\n",
    "#         prob_text = prob_text / prob_text.sum(dim=1, keepdim=True)\n",
    "#         prob_image = prob_image / prob_image.sum(dim=1, keepdim=True)\n",
    "        \n",
    "#         # 计算中间分布M（添加平滑处理）\n",
    "#         M = 0.5 * (prob_text + prob_image) + EPSILON\n",
    "#         M = M / M.sum(dim=1, keepdim=True)  # 重新归一化\n",
    "        \n",
    "#         # 安全计算对数概率（避免log(0)）\n",
    "#         log_prob_text = torch.log(torch.clamp(prob_text, min=MIN_VALUE))\n",
    "#         log_prob_image = torch.log(torch.clamp(prob_image, min=MIN_VALUE))\n",
    "#         log_M = torch.log(torch.clamp(M, min=MIN_VALUE))\n",
    "        \n",
    "#         # 计算KL散度（使用稳定版本）\n",
    "#         kl_text = F.kl_div(log_prob_text, M, reduction='none', log_target=False).sum(dim=1)\n",
    "#         kl_image = F.kl_div(log_prob_image, M, reduction='none', log_target=False).sum(dim=1)\n",
    "        \n",
    "#         # 计算JS散度\n",
    "#         js_batch = 0.5 * kl_text + 0.5 * kl_image\n",
    "        \n",
    "#         # 检测并处理无效值\n",
    "#         invalid_mask = torch.isnan(js_batch) | torch.isinf(js_batch)\n",
    "#         if invalid_mask.any():\n",
    "#             print(f\"Warning: {invalid_mask.sum().item()}/{batch_size} invalid JS values detected\")\n",
    "            \n",
    "#             # 获取有效值的均值作为替代值\n",
    "#             valid_js = js_batch[~invalid_mask]\n",
    "#             replacement = valid_js.mean() if len(valid_js) > 0 else 0.0\n",
    "#             js_batch = torch.where(invalid_mask, torch.tensor(replacement, device=js_batch.device), js_batch)\n",
    "        \n",
    "#         total_js += js_batch.sum().item()\n",
    "#         total_samples += batch_size\n",
    "    \n",
    "#     # 计算平均JS值\n",
    "#     avg_js = total_js / total_samples if total_samples > 0 else 0.0\n",
    "#     all_metrics['js'].append(avg_js)\n",
    "\n",
    "\n",
    "for i, index in enumerate(info_save_index):\n",
    "    print(f\"-----------------index {index}-----------------\")\n",
    "    \n",
    "    # 加载数据\n",
    "    input_data = input_datas[i]\n",
    "    input_data_image = input_datas_image[i]\n",
    "    \n",
    "    data_tensor = torch.stack(input_data).float()\n",
    "    data_tensor_image = torch.stack(input_data_image).float()\n",
    "    \n",
    "    # 创建数据集和加载器\n",
    "    dataset = TensorDataset(data_tensor, data_tensor_image)\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    # 初始化指标\n",
    "    total_kl = 0.0\n",
    "    total_cosine = 0.0\n",
    "    total_euclidean = 0.0\n",
    "    total_js = 0.0\n",
    "    total_pearson = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # if i<32:\n",
    "    #     continue\n",
    "    \n",
    "    for text_batch, image_batch in loader:\n",
    "        batch_size = text_batch.size(0)\n",
    "\n",
    "        # # # 1. KL散度\n",
    "        # log_text = F.log_softmax(text_batch, dim=1)\n",
    "        prob_image = F.softmax(image_batch, dim=1)\n",
    "        \n",
    "        # print(\"text_batch\", text_batch.shape)\n",
    "        # print(\"prob_image\", prob_image.shape)\n",
    "        \n",
    "        # kl_batch = F.kl_div(log_text, prob_image, reduction='none').sum(dim=1)\n",
    "        # total_kl += kl_batch.sum().item()\n",
    "        \n",
    "        # # 2. 余弦相似度\n",
    "        # cosine_batch = F.cosine_similarity(text_batch, image_batch, dim=1)\n",
    "        # total_cosine += cosine_batch.sum().item()\n",
    "        \n",
    "        # # # # 3. 欧氏距离\n",
    "        # euclidean_batch = torch.norm(text_batch - image_batch, p=2, dim=1)\n",
    "        # # print(euclidean_batch)\n",
    "        \n",
    "        # total_euclidean += euclidean_batch.sum().item()\n",
    "        \n",
    "        # # 4. JS散度\n",
    "        prob_text = F.softmax(text_batch, dim=1)\n",
    "        # M = 0.5 * (prob_text + prob_image)\n",
    "        \n",
    "        # if M.sum()<EPSILON:\n",
    "        #     M=EPSILON\n",
    "        \n",
    "        # if torch.isnan(prob_text).any():\n",
    "        #     print(f\"Tensor {i} contains NaN.\")\n",
    "        # if torch.isinf(prob_text).any():\n",
    "        #     print(f\"Tensor {i} contains Inf.\")\n",
    "        \n",
    "        # if torch.isnan(prob_image).any():\n",
    "        #     print(f\"Tensor {i} contains NaN.\")\n",
    "        # if torch.isinf(prob_image).any():\n",
    "        #     print(f\"Tensor {i} contains Inf.\")\n",
    "        js_batch=[]\n",
    "        for i in range(prob_text.shape[0]):\n",
    "            # 取当前样本的概率分布\n",
    "            p_text = prob_text[i]\n",
    "            p_image = prob_image[i]\n",
    "            \n",
    "                \n",
    "            # 计算平均分布\n",
    "            p_avg = 0.5 * (p_text + p_image)\n",
    "            \n",
    "            # 计算 KL 散度\n",
    "            kl_div_text = F.kl_div(torch.log(p_text), p_avg, reduction='batchmean')\n",
    "            kl_div_image = F.kl_div(torch.log(p_image), p_avg, reduction='batchmean')\n",
    "            # kl_div_text = torch.nn.functional.kl_div(p_text.log(), p_avg, reduction='batchmean')\n",
    "            # kl_div_image = torch.nn.functional.kl_div(p_image.log(), p_avg, reduction='batchmean')\n",
    "            \n",
    "            # if torch.isinf(kl_div_text) or torch.isnan(kl_div_text):\n",
    "            #     kl_div_text = torch.tensor(torch.log(2))\n",
    "            #     # print(\"other part kl_div_image\", kl_div_image)\n",
    "            #     # if torch.isinf(kl_div_image) or torch.isnan(kl_div_image):\n",
    "            #     #     print(\"critical\", p_text, p_image)\n",
    "            #     #     print(max(p_text), min(p_text))\n",
    "            #     #     print(max(p_image), min(p_image))\n",
    "                    \n",
    "            # if torch.isinf(kl_div_image) or torch.isnan(kl_div_image):\n",
    "            #     kl_div_image = torch.tensor(torch.log(2))\n",
    "            #     # print(\"other part kl_div_text\", kl_div_text)\n",
    "            \n",
    "            # if (torch.isinf(kl_div_text) or torch.isnan(kl_div_text)) | (torch.isinf(kl_div_image) or torch.isnan(kl_div_image)) == True:\n",
    "            #     print(\"!!!!!!!!!!!\")\n",
    "            \n",
    "            # if (torch.isinf(kl_div_text) or torch.isnan(kl_div_text)) and (torch.isinf(kl_div_image) or torch.isnan(kl_div_image)):\n",
    "            #     # print(\"avg\", p_avg)\n",
    "            #     kl_div_text = kl_div_image = torch.log(2)\n",
    "            \n",
    "            if (torch.isinf(kl_div_text) or torch.isnan(kl_div_text)) or (torch.isinf(kl_div_image) or torch.isnan(kl_div_image)):\n",
    "                kl_div_text = kl_div_image = torch.log(torch.tensor(2))/p_text.shape[0]\n",
    "            \n",
    "            # 计算 JS 散度\n",
    "            js_div = torch.tensor(0.5 * kl_div_text + 0.5 * kl_div_image)\n",
    "            \n",
    "            if torch.isinf(js_div) or torch.isnan(js_div):\n",
    "                print(\"avg\", p_avg)\n",
    "                js_div = torch.tensor(torch.log(torch.tensor(2))/p_text.shape[0])\n",
    "                print(\"TENSOR1\", p_text, \"TENSOR2\", p_image)\n",
    "                print(kl_div_text, kl_div_image)\n",
    "                print(\"max\", max(p_text), max(p_image))\n",
    "                print(\"min\", min(p_text), min(p_image))\n",
    "                print(\"norm\", torch.norm(text_batch - image_batch, p=2))\n",
    "        \n",
    "            # print(kl_div_text, kl_div_image)\n",
    "            js_batch.append(js_div)\n",
    "\n",
    "        # 将结果转换为张量\n",
    "        js_batch = torch.tensor(js_batch)\n",
    "        # print(len(js_batch), js_batch[0].shape)\n",
    "        # js_batch = 0.5 * (F.kl_div(torch.log(prob_text), M, reduction='none').sum(dim=1)) + \\\n",
    "        #            0.5 * (F.kl_div(torch.log(prob_image), M, reduction='none').sum(dim=1))\n",
    "        \n",
    "        # print(js_batch)\n",
    "        \n",
    "        # def check_nan_inf_and_print(tensor, name):\n",
    "        #     if torch.isnan(tensor).any():\n",
    "        #         print(f\"{name} contains NaN.\")\n",
    "        #         print(f\"Tensor {name} stats: min={tensor.min()}, max={tensor.max()}, mean={tensor.mean()}\")\n",
    "        #     if torch.isinf(tensor).any():\n",
    "        #         print(f\"{name} contains Inf.\")\n",
    "        #         print(f\"Tensor {name} stats: min={tensor.min()}, max={tensor.max()}, mean={tensor.mean()}\")\n",
    "        \n",
    "        # # 计算 KL 散度\n",
    "        # kl_text = F.kl_div(torch.log(prob_text), M, reduction='none')\n",
    "        # kl_image = F.kl_div(torch.log(prob_image), M, reduction='none')\n",
    "\n",
    "        # # 检查 KL 散度\n",
    "        # check_nan_inf_and_print(kl_text, \"kl_text\")\n",
    "        # check_nan_inf_and_print(kl_image, \"kl_image\")\n",
    "\n",
    "        # valid_js = js_batch[~torch.isnan(js_batch) & ~torch.isinf(js_batch)]\n",
    "        # print(js_batch)\n",
    "        total_js += sum(js_batch) #.item()\n",
    "        \n",
    "        # print(js_batch)\n",
    "        # print(\"max\", max(js_batch))\n",
    "        # # # 5. 皮尔逊相关系数\n",
    "        # mean_text = text_batch.mean(dim=1, keepdim=True)\n",
    "        # mean_image = image_batch.mean(dim=1, keepdim=True)\n",
    "        # cov = ((text_batch - mean_text) * (image_batch - mean_image)).sum(dim=1)\n",
    "        # std_text = torch.sqrt(((text_batch - mean_text)**2).sum(dim=1))\n",
    "        # std_image = torch.sqrt(((image_batch - mean_image)**2).sum(dim=1))\n",
    "        # pearson_batch = cov / (std_text * std_image + 1e-8)  # 避免除零\n",
    "        # total_pearson += pearson_batch.sum().item()\n",
    "        \n",
    "        total_samples += batch_size\n",
    "    \n",
    "    # 计算平均指标\n",
    "    # all_metrics['kl'].append(total_kl / total_samples)\n",
    "    # all_metrics['cosine'].append(total_cosine / total_samples)\n",
    "    # all_metrics['euclidean'].append(total_euclidean / total_samples)\n",
    "    print(\"append\", total_js / total_samples)\n",
    "    all_metrics['js'].append(total_js / total_samples)\n",
    "    # all_metrics['pearson'].append(total_pearson / total_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b28ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果\n",
    "for metric_name, values in all_metrics.items():\n",
    "    with open(f'result/{prefix}{metric_name}_layerwise.txt', 'w') as f:\n",
    "        for value in values:\n",
    "            f.write(f\"{value}\\n\")\n",
    "    \n",
    "    # 绘制图表\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(values, marker='o')\n",
    "    plt.title(f'Layer-wise {metric_name.upper()} Comparison')\n",
    "    plt.xlabel('Layer Index')\n",
    "    plt.ylabel(metric_name.capitalize())\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'result/{prefix}{metric_name}_layerwise.pdf', format='pdf')\n",
    "    plt.close()\n",
    "\n",
    "# # 保存结果到文件\n",
    "# written_file = f'result/{prefix}direct_kls_layerwise.txt'\n",
    "# with open(written_file, 'w') as f:\n",
    "#     for kl in all_kls:\n",
    "#         f.write(f\"{kl}\\n\")\n",
    "# print(f\"Results written to: {written_file}\")\n",
    "\n",
    "# # 绘制折线图\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(all_kls[:-1], marker='o', linestyle='-', color='b')\n",
    "# plt.title('Direct KL Divergence between Text and Image Features')\n",
    "# plt.xlabel('Layer Index')\n",
    "# plt.ylabel('KL Divergence')\n",
    "# plt.grid(True)\n",
    "# plt.savefig(f'result/{prefix}direct_kls_layerwise.pdf', format='pdf')\n",
    "# plt.close()\n",
    "# print(\"Plot saved as PDF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
